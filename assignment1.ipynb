{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "098b2971-5d7a-4d7f-aec2-3400a31a72b0",
      "metadata": {
        "id": "098b2971-5d7a-4d7f-aec2-3400a31a72b0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n",
        "## Econ 8310 - Business Forecasting\n",
        "\n",
        "This assignment will make use of the models covered in Lessons 1 to 3. Models include:\n",
        "\n",
        "- Vector AutoRegressive Moving Average (VARMA) Models\n",
        "- Generalized Additive Models (GAMs)\n",
        "- Exponential Smoothing models\n",
        "\n",
        "Your job will be to forecast the number of taxi trips requested during each hour in a week in New York City, utilizing past data about taxi trips in New York City. Your grade will be assigned based on the performance of your code, and will be based primarily on:\n",
        "\n",
        "- Your code executing without errors\n",
        "- Storing your models to make predictions on new data\n",
        "- Making reasonable predictions based on the data provided\n",
        "\n",
        "The data is available at [https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_train.csv](https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_train.csv)\n",
        "\n",
        "To complete this assignment, your code will need to contain the following:\n",
        "\n",
        "- One valid model. This can be one model of any kind covered in class to this point (see list above). For your model, be sure that you structure the model code as follows:\n",
        "\n",
        "    - A forecasting algorithm named `model` using the implementation of one of the four models covered in weeks 1 to 3 (don't use other libraries, since I can't keep track of all of them). This model will use the number of trips in an hour as the dependent variable, and may or may not use exogenous variables from the remainder of the dataset.\n",
        "    - A fitted model named `modelFit`. This should be a model instance capable of generating forecasts by incorporating new data in the same shape as the data used in part (1).\n",
        "    - A vector of forecasts using the data from the test period named `pred`. You should predict each hour in January of the year following our training data (for 744 total predicted hours).\n",
        "    \n",
        "To make predictions, you can use the test data set found at the following link: [https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_test.csv](https://github.com/dustywhite7/econ8310-assignment1/raw/main/assignment_data_test.csv)\n",
        "\n",
        "While the .ipynb file is a notebook for you to use as you experiment, you must put **all code necessary to complete this assignment into the file called `assignment1.py` found in the file tree**. If your notebook can be run as a script (ie - runs without errors when you restart the kernel and run all cells), then you can simply export your notebook to a .py file and overwrite `assignment1.py`.\n",
        "\n",
        "**Note:** While all models from weeks 1 to 3 are available to you, they may not all be good fits to the data. I recommend considering the data carefully, then choosing 2-3 models to try. See which models seem to perform best on this data, and implement the best choice for the final submission of the project.\n"
      ],
      "metadata": {
        "id": "l_haNnwlgxmQ"
      },
      "id": "l_haNnwlgxmQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "# Load training data\n",
        "train = pd.read_csv(\"assignment_data_train.csv\")\n",
        "\n",
        "# Use trips as a time series\n",
        "y = train[\"trips\"].astype(float).values\n",
        "\n",
        "# Define the model\n",
        "model = ExponentialSmoothing(\n",
        "    y,\n",
        "    trend=\"add\",\n",
        "    seasonal=\"mul\",\n",
        "    seasonal_periods=24\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "modelFit = model.fit(optimized=True)\n",
        "\n",
        "# Forecast January (744 hours)\n",
        "pred = modelFit.forecast(744)\n",
        "\n",
        "# Ensure correct format\n",
        "pred = np.array(pred, dtype=float)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tj1_C-Dg0nS",
        "outputId": "e94ca783-fc8d-43d5-c4a8-ee6ad6eea859"
      },
      "id": "1tj1_C-Dg0nS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/statsmodels/tsa/holtwinters/model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}